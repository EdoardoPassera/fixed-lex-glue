CaseHOLD (--max_train_samples 10000)
					 VALIDATION                                      | TEST
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
                  bert-base-uncased: MICRO-F1: 71.1	 ± 0.0	MACRO-F1: 71.1	 ± 0.0	 | MICRO-F1: 68.1	MACRO-F1: 68.1	
                       roberta-base: MICRO-F1: nan	 ± nan	MACRO-F1: nan	 ± nan	 | MICRO-F1: nan	MACRO-F1: nan	
             microsoft/deberta-base: MICRO-F1: nan	 ± nan	MACRO-F1: nan	 ± nan	 | MICRO-F1: nan	MACRO-F1: nan	
       allenai/longformer-base-4096: MICRO-F1: nan	 ± nan	MACRO-F1: nan	 ± nan	 | MICRO-F1: nan	MACRO-F1: nan	
        google/bigbird-roberta-base: MICRO-F1: nan	 ± nan	MACRO-F1: nan	 ± nan	 | MICRO-F1: nan	MACRO-F1: nan	
    nlpaueb/legal-bert-base-uncased: MICRO-F1: nan	 ± nan	MACRO-F1: nan	 ± nan	 | MICRO-F1: nan	MACRO-F1: nan	
            zlucia/custom-legalbert: MICRO-F1: nan	 ± nan	MACRO-F1: nan	 ± nan	 | MICRO-F1: nan	MACRO-F1: nan	
                      roberta-large: MICRO-F1: nan	 ± nan	MACRO-F1: nan	 ± nan	 | MICRO-F1: nan	MACRO-F1: nan
   nlpaueb/legal-bert-small-uncased: MICRO-F1: 72.6	 ± 0.0	MACRO-F1: 72.6   ± 0.0	 | MICRO-F1: 71.0	MACRO-F1: 71.0


SCOTUS
                                     VALIDATION                                      	 | TEST
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
                  bert-base-uncased: MICRO-F1: 66.1	 ± 0.0	MACRO-F1: 41.2	 ± 0.0	 | MICRO-F1: 65.9	MACRO-F1: 38.8	
                       roberta-base: MICRO-F1: nan	 ± nan	MACRO-F1: nan	 ± nan	 | MICRO-F1: nan	MACRO-F1: nan	
             microsoft/deberta-base: MICRO-F1: nan	 ± nan	MACRO-F1: nan	 ± nan	 | MICRO-F1: nan	MACRO-F1: nan	
       allenai/longformer-base-4096: MICRO-F1: nan	 ± nan	MACRO-F1: nan	 ± nan	 | MICRO-F1: nan	MACRO-F1: nan	
        google/bigbird-roberta-base: MICRO-F1: nan	 ± nan	MACRO-F1: nan	 ± nan	 | MICRO-F1: nan	MACRO-F1: nan	
    nlpaueb/legal-bert-base-uncased: MICRO-F1: nan	 ± nan	MACRO-F1: nan	 ± nan	 | MICRO-F1: nan	MACRO-F1: nan	
            zlucia/custom-legalbert: MICRO-F1: nan	 ± nan	MACRO-F1: nan	 ± nan	 | MICRO-F1: nan	MACRO-F1: nan	
                      roberta-large: MICRO-F1: nan	 ± nan	MACRO-F1: nan	 ± nan	 | MICRO-F1: nan	MACRO-F1: nan	


ECTHR (Task A) (--max_train_samples 9000)
                                    VALIDATION                                      	 | TEST
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
                  bert-base-uncased: MICRO-F1: 59.6	 ± 0.0	MACRO-F1: 48.2	 ± 0.0	 | MICRO-F1: 55.8	MACRO-F1: 44.2	
                       roberta-base: MICRO-F1: 63.6	 ± 0.0	MACRO-F1: 56.6	 ± 0.0	 | MICRO-F1: 60.4	MACRO-F1: 50.2
             microsoft/deberta-base: MICRO-F1: 64.4	 ± 0.0	MACRO-F1: 57.9	 ± 0.0	 | MICRO-F1: 61.9	MACRO-F1: 53.4	
    nlpaueb/legal-bert-base-uncased: MICRO-F1: 61.6	 ± 0.0	MACRO-F1: 51.5	 ± 0.0	 | MICRO-F1: 59.4	MACRO-F1: 48.0	
   nlpaueb/legal-bert-small-uncased: MICRO-F1: 64.4	 ± 0.0	MACRO-F1: 50.9	 ± 0.0	 | MICRO-F1: nan	MACRO-F1: nan		
            zlucia/custom-legalbert: MICRO-F1: 63.5	 ± 0.0	MACRO-F1: 53.9	 ± 0.0	 | MICRO-F1: 60.9	MACRO-F1: 50.3	
                      roberta-large: MICRO-F1: 66.5	 ± 0.0	MACRO-F1: 61.3	 ± 0.0	 | MICRO-F1: 64.7	MACRO-F1: 57.4	